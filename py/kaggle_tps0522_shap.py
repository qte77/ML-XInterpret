# -*- coding: utf-8 -*-
"""kaggle-tps0522-shap.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ftFRMHDg1sjeBzJ98Qrx4HyUhteYwBK

# Using SHAP for feature selection

Source
* [Analysing Interactions with SHAP](https://www.kaggle.com/code/wti200/analysing-interactions-with-shap)

## Resources
* [EDA which makes sense](https://www.kaggle.com/code/ambrosm/tpsmay22-eda-which-makes-sense) for almost balanced binary target
* Rank MI-Score, Corr and their mean [Mixing Correlation and Mutual Information](https://www.kaggle.com/code/pourchot/tps-2022-05-important-features-updated)
* [Gradient Boosting Quickstart](https://www.kaggle.com/ambrosm/tpsmay22-gradient-boosting-quickstart)
* [Basic SHAP Interaction Value Example in XGBoost](https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Basic%20SHAP%20Interaction%20Value%20Example%20in%20XGBoost.html)
* [Understanding Tree SHAP for Simple Models](https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Understanding%20Tree%20SHAP%20for%20Simple%20Models.html)
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# !pip uninstall matplotlib -y
# !pip install matplotlib==3.1.3
# !pip uninstall imgaug -y
# #!pip install imgaug<0.2.7
# !pip install mplcyberpunk
# !pip install shap kaggle watermark

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from pandas.io.parsers.python_parser import count_empty_vals
import numpy as np

import matplotlib.pyplot as plt
import matplotlib
from matplotlib import gridspec
import seaborn as sns

for i in range(2):
  print('Trying to import mplcyberpunk')
  try:
    import mplcyberpunk
  except Exception as e:
    print(str(e))

from sklearn.model_selection import KFold, cross_val_score, train_test_split
import shap
import xgboost as xgb
from lightgbm import LGBMClassifier
from sklearn.metrics import roc_auc_score, roc_curve
from tqdm import tqdm

from google.colab import drive
import json

import warnings
import os

import watermark
# %load_ext watermark

# Commented out IPython magic to ensure Python compatibility.
# %watermark -a qe77 -gu qte77 -ws qte77 -u -i -v -iv
#%watermark?

# pkg cfg
warnings.filterwarnings("ignore")
pd.set_option('display.max_columns', None)
# runtime configuration of matplotlib
plt.style.use("cyberpunk")
plt.rc("figure", 
    autolayout=False, 
    figsize=(20, 10),
)
plt.rc(
    "axes",
    labelweight="bold",
    labelsize="large",
    titleweight="bold",
    titlesize=20,
    titlepad=10,
)

#drive.mount('/gdrive')

"""* https://github.com/Kaggle/kaggle-api
* no username in notebooks https://github.com/Kaggle/kaggle-api/issues/305
```
#read kaggle username and secret
#for script
!export KAGGLE_USERNAME=
!export KAGGLE_KEY=
#or
cfg="~/.kaggle/kaggle.json"
!chmod 600 $cfg
!cat $cfg
!ls -la $cfg
```
"""

kaggle_json="k.json" #or /gdrive
!touch $kaggle_json
#!echo '{"username":"###","key":"###"}' > k.json
!cat $kaggle_json
!ls -la

#if "~/.kaggle/kaggle.json" not working with colab
with open(kaggle_json, 'r') as j:
  data = json.loads(j.read())
  os.environ['KAGGLE_USERNAME'] = data['username']
  os.environ['KAGGLE_KEY'] = data['key']

downdir="/content/SHAP"
src="tabular-playground-series-may-2022"
os.environ['kaggle_downdir'] = downdir
os.environ['kaggle_src'] = src

# Commented out IPython magic to ensure Python compatibility.
# %%time
# %%shell
# if [ ! -d $kaggle_downdir ]; then
# mkdir $kaggle_downdir;
# fi
# cd $kaggle_downdir
# kaggle competitions download -c tabular-playground-series-may-2022 -p $kaggle_downdir
# unzip -n $kaggle_src -d $kaggle_src
# #rm -f $kaggle_srcn
# ls -la

# Commented out IPython magic to ensure Python compatibility.
# %%time
# train_raw = pd.read_csv(f'{downdir}/{src}/train.csv',index_col='id')
# test_raw = pd.read_csv(f'{downdir}/{src}/test.csv',index_col='id')

train_raw.dtypes

train_raw.info()
train_raw['f_27']

fig = plt.figure(figsize=(5, 2))
ax = fig.add_subplot(111)
table_vals = [
              [train_raw.shape[0], test_raw.shape[0]], #rows
              [train_raw.shape[1], test_raw.shape[1]], #cols
              [count_empty_vals(train_raw), count_empty_vals(test_raw)], #not null
              [15, 15], #int64
              [16, 16], #np.float64
              [1, 0] #object
              ]

# Draw table
the_table = plt.table(cellText=table_vals,
                      colWidths=[0.08]*2,
                      rowLabels=['#rows', '#columns', '%missing', "int64", "float64", "object"],
                      colLabels=['Train', 'Test'],
                      loc='center',
                      cellLoc='center',
                      rowColours =["purple"] * 6,  
                      colColours =["purple"] * 6,
                      cellColours=[['r', 'r'], ['r', 'r'], ['r', 'r'], ['r', 'r'], ['r', 'r'], ['r', 'r']]
                      )
the_table.auto_set_font_size(False)
the_table.set_fontsize(16)
the_table.scale(4, 4)
ax.grid(False)
ax.axis('tight')
ax.axis('off')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# #EDA
# # From https://www.kaggle.com/ambrosm/tpsmay22-eda-which-makes-sense
# %%time
# for i in range(10):
#     train_raw[f'ch{i}'] = train_raw.f_27.str.get(i).apply(ord) - ord('A')
#     train_raw["unique_characters"] = train_raw.f_27.apply(lambda s: len(set(s)))
# 
# features = [col for col in train_raw.columns if col != "target" and col !="f_27"]
# X=train_raw[features]
# y=train_raw["target"]
# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state = 42)

X

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Train model
# lgbm_model = LGBMClassifier(n_estimators=50, min_child_samples=20, random_state=1307)
# print('Fit model.')
# for i in tqdm(range(100)):
#   lgbm_model.fit(X_train.values, y_train)
# print('Predict probs.')
# for i in tqdm(range(100)):
#   y_val_pred = lgbm_model.predict_proba(X_val.values)[:,1]
# score = roc_auc_score(y_val, y_val_pred)
# print(f"\nValidation AUC:{(score):.3f}")

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Using a random sample of the dataframe for better time computation
# X_sampled = X_val.sample(2000, random_state=1307)
# 
# # explain the model's predictions using SHAP values
# print('SHAP Tree Explainer of full model.')
# for i in tqdm(range(100)):
#   explainer = shap.TreeExplainer(lgbm_model)
# print('Explainer Values of rand sampled X.')
# for i in tqdm(range(100)):
#     shap_values = explainer.shap_values(X_sampled)
# 
# #Get SHAP interaction values. Beware it is time consuming to calculate the interaction values.
# #approx. 9h with 1x CPU
# print('SHAP interactiovn values of sampled X.')
# for i in tqdm(range(100)):
#   shap_interaction = explainer.shap_interaction_values(X_sampled)
# print(np.shape(shap_interaction))
# 
# #with open('/gdrive/My Drive/foo.txt', 'w') as f:
# #  f.write('Hello Google Drive!')
# #!cat '/gdrive/My Drive/foo.txt'
# 
# #loaded_arr = np.loadtxt('../input/shap-interaction/shap_interaction_20k.txt')
# #load_original_arr = loaded_arr.reshape(
#     #loaded_arr.shape[0], loaded_arr.shape[1] // shap_interaction.shape[2], shap_interaction.shape[2])
# #    loaded_arr.shape[0], loaded_arr.shape[1] // 41, 41)
# 
# #shap_interaction = load_original_arr

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Get absolute mean of matrices
# mean_shap = np.abs(shap_interaction).mean(0)
# df = pd.DataFrame(mean_shap, index=X.columns, columns=X.columns)
# 
# # times off diagonal by 2
# df.where(df.values == np.diagonal(df),df.values*2, inplace=True)
# 
# # display 
# fig = plt.figure(figsize=(35, 20), facecolor='#002637', edgecolor='r')
# ax = fig.add_subplot()
# sns.heatmap(df.round(decimals=3), cmap='coolwarm', annot=True, fmt='.6g', cbar=False, ax=ax, )
# ax.tick_params(axis='x', colors='w', labelsize=15, rotation=90)
# ax.tick_params(axis='y', colors='w', labelsize=15)
# 
# plt.suptitle("SHAP interaction values", color="white", fontsize=60, y=0.97)
# plt.yticks(rotation=0) 
# plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #plot feature interaction
# def plot_feature_interaction(f1, f2):
#     # dependence plot
#     fig = plt.figure(tight_layout=True, figsize=(20,10))
#     spec = gridspec.GridSpec(ncols=3, nrows=2, figure=fig)
# 
# 
#     ax0 = fig.add_subplot(spec[0, 0])
#     minv, maxv = np.percentile(X_sampled, [1, 99])
#     shap.dependence_plot(f1, shap_values[1], X_sampled, display_features=X_sampled, interaction_index=f2, ax=ax0, show=False)
#     ax0.yaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax0.xaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax0.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red
#     ax0.tick_params(axis='y', colors='white')    #setting up X-axis tick color to red
#     ax0.set_title(f'SHAP main effect', fontsize=10)
# 
#     ax1 = fig.add_subplot(spec[0, 1])
#     shap.dependence_plot((f1, f2), shap_interaction, X_sampled, display_features=X_sampled, ax=ax1, axis_color='w', show=False)
#     ax1.yaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax1.xaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax1.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red
#     ax1.tick_params(axis='y', colors='white')    #setting up X-axis tick color to red
#     ax1.set_title(f'SHAP interaction effect', fontsize=10)
# 
# 
#     temp = pd.DataFrame({f1: train_raw[f1].values,
#                     'target': train_raw.target.values})
#     temp = temp.sort_values(f1)
#     temp.reset_index(inplace=True)
#     
#     ax3 = fig.add_subplot(spec[1, 0])
#     sns.scatterplot(x=temp[f1], y=temp.target.rolling(15000, center=True).mean(), data=temp, ax=ax3, s=2)
#     ax3.set_title('How the target probability depends on f_02', fontsize=10)
# 
#     temp = pd.DataFrame({f1: train_raw.loc[train_raw["f_30"]==2,f1].values,
#                     'target': train_raw.loc[train_raw["f_30"]==2,'target'].values})
#     temp = temp.sort_values(f1)
#     temp.reset_index(inplace=True)
#     
#     ax4 = fig.add_subplot(spec[1, 1])
#     sns.scatterplot(x=temp[f1], y=temp.target.rolling(15000, center=True).mean(), data=temp, ax=ax4, s=2)
#     ax4.set_title('How the target probability depends on f_24 & f_30==2', fontsize=10)
# 
# 
#     temp = pd.DataFrame({f1: train_raw.loc[train_raw["f_30"]!=2,f1].values,
#                     'target': train_raw.loc[train_raw["f_30"]!=2,'target'].values})
#     temp = temp.sort_values(f1)
#     temp.reset_index(inplace=True)
#     
#     ax5 = fig.add_subplot(spec[1, 2])
#     sns.scatterplot(x=temp[f1], y=temp.target.rolling(15000, center=True).mean(), data=temp, ax=ax5, s=2)
#     ax5.set_title('How the target probability depends on f_24 & f_30!=2', fontsize=10)
#     
#     plt.suptitle("Feature Interaction Analysis\n f_24 and f_30", fontsize=30, y=1.15)
#     fig.tight_layout()
# 
#     plt.show()
# 
# plt.style.use("cyberpunk")
# 
# f1='f_24'
# f2='f_30'
# plot_feature_interaction(f1, f2)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #plot function
# plt.style.use("cyberpunk")
# 
# def plot_feature_interaction(f1, f2):
#     # dependence plot
#     fig = plt.figure(tight_layout=True, figsize=(20,10))
#     spec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)
# 
# 
#     ax0 = fig.add_subplot(spec[0, 0])
#     shap.dependence_plot(f1, shap_values[1], X_sampled, display_features=X_sampled, interaction_index=None, ax=ax0, show=False)
#     ax0.yaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax0.xaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax0.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red
#     ax0.tick_params(axis='y', colors='white')    #setting up X-axis tick color to red
#     ax0.set_title(f'SHAP main effect', fontsize=10)
# 
#     ax1 = fig.add_subplot(spec[0, 1])
#     shap.dependence_plot((f1, f2), shap_interaction, X_sampled, display_features=X_sampled, ax=ax1, axis_color='w', show=False)
#     ax1.yaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax1.xaxis.label.set_color('white')          #setting up Y-axis label color to blue
#     ax1.tick_params(axis='x', colors='white')    #setting up X-axis tick color to red
#     ax1.tick_params(axis='y', colors='white')    #setting up X-axis tick color to red
#     ax1.set_title(f'SHAP interaction effect', fontsize=10)
# 
#     ax2 = fig.add_subplot(spec[1, 0])
#     sns.scatterplot(x=f1, y=f2, data=train_raw, hue="target", ax=ax2, s=2)
#     ax2.text(-1.5, -5, "1", fontsize=18, verticalalignment='top', rotation="horizontal", color="k", fontproperties="smallcaps")
#     ax2.text(0, 1, "2", fontsize=18, verticalalignment='top', rotation="horizontal", color="k", fontproperties="smallcaps")
#     ax2.text(1, 7, "3", fontsize=18, verticalalignment='top', rotation="horizontal", color="k", fontproperties="smallcaps")
# 
#     ax2.set_title(f'scatter plot', fontsize=10)
# 
#     temp = pd.DataFrame({f1: train_raw[f1].values,'target': train_raw.target.values})
#     temp = temp.sort_values(f1)
#     temp.reset_index(inplace=True)
#     
#     ax3 = fig.add_subplot(spec[1, 1])
#     sns.scatterplot(x=temp[f1], y=temp.target.rolling(15000, center=True).mean(), data=temp, ax=ax3, s=2)
#     ax3.set_title('How the target probability depends on f_02', fontsize=10)
#     
#     plt.suptitle("Feature Interaction Analysis\n f_02 and f_21", fontsize=30, y=1.15)
#     plt.show()
# 
# f1='f_02'
# f2='f_21'
# plot_feature_interaction(f1, f2)

